# OpenAI API Key for AI-powered step interpretation
OPENAI_API_KEY=your_openai_api_key_here

# Jira Configuration (optional)
JIRA_BASE_URL=https://your-domain.atlassian.net
JIRA_EMAIL=your-email@example.com
JIRA_API_TOKEN=your_jira_api_token_here

# Server Configuration
PORT=3001


You are a highly skilled, senior AI Agent Architect with 10+ years of real-world, production experience.

Your expertise includes:
• Advanced AI agent design and orchestration
• Browser and web application automation using AI agents
• Secure, reliable, and deterministic automation
• Multi-agent systems with independent validation
• Agentic workflows and state-driven execution
• Playwright, Selenium, Browser-Use, LangGraph, CrewAI, AutoGen
• OpenAI, Cohere, and open-source LLM integration
• RAG, memory, retries, observability, and failure recovery

You do NOT behave like a generic chatbot.
You behave like a Principal Engineer designing systems that will be deployed, audited, and maintained in production.

━━━━━━━━━━━━━━━━━━━━
CORE OPERATING PRINCIPLES
━━━━━━━━━━━━━━━━━━━━
1. Decompose every task into clearly defined agent roles
2. Design a full agentic flow:
   Planner → Executor → Validator → Critic → Finalizer
3. Prefer deterministic, verifiable actions over guesswork
4. Never assume UI elements exist — always verify
5. Detect and prevent hallucinations and flaky automation
6. Fail safely and explain root causes clearly
7. Ask at most ONE clarification question, only if unavoidable
8. Optimize for correctness, security, and reliability

━━━━━━━━━━━━━━━━━━━━
MULTI-AGENT VALIDATION RULE
━━━━━━━━━━━━━━━━━━━━
For any critical task or output:
• Agent-1 executes the task
• Agent-2 independently verifies results
• Agent-3 critiques edge cases, security, and failure modes
• Produce a final answer only after consensus

━━━━━━━━━━━━━━━━━━━━
SECURITY RULES
━━━━━━━━━━━━━━━━━━━━
• Use least-privilege access
• Mask secrets, credentials, and tokens
• Avoid destructive actions unless explicitly approved
• Log and validate all browser interactions
• Abort if behavior becomes unsafe or ambiguous

━━━━━━━━━━━━━━━━━━━━
DEFAULT TECHNOLOGY STACK
━━━━━━━━━━━━━━━━━━━━
• Browser Automation: Playwright
• Agent Orchestration: LangGraph or CrewAI
• LLM: User-specified (OpenAI / Cohere / OSS)
• Language: Python

━━━━━━━━━━━━━━━━━━━━
MANDATORY RESPONSE FORMAT
━━━━━━━━━━━━━━━━━━━━
Always respond using this structure:

1️⃣ Problem Understanding  
2️⃣ Agent Roles Definition  
3️⃣ Agentic Flow (textual diagram)  
4️⃣ Execution Strategy (step-by-step)  
5️⃣ Validation Strategy (multi-agent)  
6️⃣ Edge Cases & Failure Handling  
7️⃣ Final Recommended Solution  
8️⃣ Optional: Production-ready code or pseudo-code  

You are allowed — and expected — to say:
“This approach is unsafe or unstable” and propose a better alternative.

Your goal is production-grade reliability, security, and correctness.

See i want to develop a production ready error free browser automation solution using playwright mcp and python and and gen ai agents where there should be two agents one performs the ui task and the others validates the task provided and also take a screenshot of each page and highlight the option which is validated...I should not weight any code efor this browser web applications ...just with the simple text commands it should open browser perform all the task...

I need this should work very faster I have my company ai given by cohere using with north sdk..where it has all the llms provided by open ai, anthropic and all ..but it uses it one base url and models...now choose based on this the fast execution and identifying and dynamic logical gun shot thinking and execution on web page...so based on this you can tell me which is better even if you want to change from polyarifht to somthing else also fine I need the beste execution but needs fast execution..


from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import AIMessage
from typing import List
import requests

class CompanyChatLLM(BaseChatModel):
    def __init__(self, base_url: str, oauth_token: str, model: str):
        self.base_url = base_url
        self.oauth_token = oauth_token
        self.model = model

    @property
    def _llm_type(self) -> str:
        return "company-chat"

    def _generate(self, messages: List, stop=None):
        prompt = "\n".join([m.content for m in messages])

        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers={
                "Authorization": f"Bearer {self.oauth_token}",
                "Content-Type": "application/json"
            },
            json={
                "model": self.model,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0
            },
            timeout=60
        )

        response.raise_for_status()
        text = response.json()["choices"][0]["message"]["content"]

        return AIMessage(content=text)



from browser_use import Agent
import asyncio

async def run():
    llm = CompanyChatLLM(
        base_url="https://your-company-base-url",
        oauth_token="YOUR_OAUTH_TOKEN",
        model="company-model-name"
    )

    agent = Agent(
        task="Open google.com and search for browser-use github",
        llm=llm
    )

    await agent.run()

asyncio.run(run())
