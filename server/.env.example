# OpenAI API Key for AI-powered step interpretation
OPENAI_API_KEY=your_openai_api_key_here

# Jira Configuration (optional)
JIRA_BASE_URL=https://your-domain.atlassian.net
JIRA_EMAIL=your-email@example.com
JIRA_API_TOKEN=your_jira_api_token_here

# Server Configuration
PORT=3001

from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.messages import AIMessage
from langchain_core.outputs import ChatGeneration, ChatResult
from typing import List
import requests

class CompanyChatLLM(BaseChatModel):
    def __init__(self, base_url: str, oauth_token: str, model: str):
        super().__init__()
        self.base_url = base_url
        self.oauth_token = oauth_token
        self.model = model

    @property
    def _llm_type(self) -> str:
        return "company-chat"

    def _generate(self, messages: List, stop=None, **kwargs) -> ChatResult:
        prompt = "\n".join([m.content for m in messages])

        response = requests.post(
            f"{self.base_url}/chat/completions",
            headers={
                "Authorization": f"Bearer {self.oauth_token}",
                "Content-Type": "application/json"
            },
            json={
                "model": self.model,
                "messages": [
                    {"role": "user", "content": prompt}
                ],
                "temperature": 0
            },
            timeout=60
        )

        response.raise_for_status()
        text = response.json()["choices"][0]["message"]["content"]

        message = AIMessage(content=text)
        generation = ChatGeneration(message=message)

        return ChatResult(generations=[generation])
